{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a3430d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Datenjournalismus in Python - \n",
    "# Eine praktische Einführung in die Programmierung\n",
    "\n",
    "\n",
    "### Natalie Widmann\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Wintersemester 2022 / 2023\n",
    "\n",
    "\n",
    "Universität Leipzig\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a590031",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Projektpräsentation - 26. Januar 2023\n",
    "\n",
    "- insgesamt 11 Teams mit 8 unterschiedlichen Projekten\n",
    "- pro Team 5 - max.7 Minuten\n",
    "- Projektpräsentation gibt 10 von 40 Punkten\n",
    "- Inhalte\n",
    "    - Projektbeschreibung und aktueller Stand\n",
    "    - Was ist die wichtigste Zeile oder der wichtigster Absatz im Code und warum?\n",
    "    - Was war die größte Herausforderung? Wie habt ihr diese gelöst?\n",
    "- Slides bis zum 25.1 um 12 Uhr an natalie_widmann@posteo.net\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e785d50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vorlesung 11 -  Dataframes & Textanalyse\n",
    "\n",
    " ### Inhalte\n",
    " \n",
    " - Daten zusammenfügen\n",
    " - Quiz\n",
    " - Textanalyse\n",
    " - Kurs Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434e6545",
   "metadata": {},
   "source": [
    "# Teil 1: Daten aneinander fügen\n",
    "\n",
    "\n",
    "![Timeline](../imgs/concat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n",
    "        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n",
    "        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n",
    "        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "df3 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"A8\", \"A9\", \"A10\", \"A11\"],\n",
    "        \"B\": [\"B8\", \"B9\", \"B10\", \"B11\"],\n",
    "        \"C\": [\"C8\", \"C9\", \"C10\", \"C11\"],\n",
    "        \"D\": [\"D8\", \"D9\", \"D10\", \"D11\"],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94ad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c284d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f213a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7027c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee454c2d",
   "metadata": {},
   "source": [
    "### Als Spalten aneinander fügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ac171",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df2, df3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99171479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc828e1e",
   "metadata": {},
   "source": [
    "### DataFrames mit unterschiedlichen Spalten zusammenfügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame(\n",
    "    {\n",
    "        \"B\": [\"B2\", \"B3\", \"B6\", \"B7\"],\n",
    "        \"D\": [\"D2\", \"D3\", \"D6\", \"D7\"],\n",
    "        \"F\": [\"F2\", \"F3\", \"F6\", \"F7\"],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de70f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df4], axis=0)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1, df4], axis=0, join='inner')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5f7be6",
   "metadata": {},
   "source": [
    "## Datensätze zusammensetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5930d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d1 = {'Stadt': ['Dresden', 'Leipzig', 'Chemnitz'],\n",
    "      'Einwohner': [550000, 600000, 240000],\n",
    "      'Bürgermeister': ['Dirk Hilbert', 'Burkhard Jung', 'Sven Schultze'],\n",
    "      'GemeindeID': ['14612000', '14713000', '14511000']\n",
    "     }\n",
    "df1 = pd.DataFrame(d1)\n",
    "\n",
    "df2 = pd.DataFrame({'Stadt': ['Zwickau', 'Chemnitz', 'Görlitz'],\n",
    "                    'Bevölkerungsdichte': [844, 1100, 822]\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a55db8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c2155",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c156e",
   "metadata": {},
   "source": [
    "### Pandas `merge` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.merge(df2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.merge(df2, how='outer')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.merge(df2, how='left')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911862c",
   "metadata": {},
   "source": [
    "### DataFrame auf speziellen Spalten zusammenführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d724ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "d1 = {'Stadt': ['Dresden', 'Leipzig', 'Chemnitz'],\n",
    "      'Einwohner': [550000, 60000, 240000],\n",
    "      'Bürgermeister': ['Dirk Hilbert', 'Burkhard Jung', 'Sven Schultze'],\n",
    "      'GemeindeID': ['14612000', '14713000', '14511000']\n",
    "     }\n",
    "df1 = pd.DataFrame(d1)\n",
    "\n",
    "df2 = pd.DataFrame({'Stadt': ['Zwickau', 'Chemnitz', 'Görlitz'],\n",
    "                    'Bevölkerungsdichte': [844, 1100, 822],\n",
    "                    'Bürgermeister': ['Constance Arndt', 'Sven Schultze', 'Dirk Hilbert'],\n",
    "                   })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3856d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.merge(df2, on='Bürgermeister')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.merge(df2, on='Stadt', how='outer')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a8e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.merge(df2, on=['Stadt', 'Bürgermeister'], how='outer')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c2d909",
   "metadata": {},
   "source": [
    "# Quiz Time\n",
    "\n",
    "https://ahaslides.com/8QTDO\n",
    "\n",
    "![QR Quiz](../imgs/qr_quiz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc16261",
   "metadata": {},
   "source": [
    "# Teil 2: Textanalyse\n",
    "\n",
    "## Wahlprogramme zur Bundestagswahl 2021 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/wahlprogramme/fdp.txt'\n",
    "with open(path) as f:\n",
    "    fdp_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df048dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b519310a",
   "metadata": {},
   "source": [
    "### Alle Wahlprogramme einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae43966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Files in einem Ordner ausgeben\n",
    "import os\n",
    "\n",
    "path = '../data/wahlprogramme/'\n",
    "for file_path in os.listdir(path):\n",
    "    print(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fcc5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Files in einem Ordner einlesen\n",
    "path = '../data/wahlprogramme/'\n",
    "programs = []\n",
    "for file_path in os.listdir(path):\n",
    "    with open(path + file_path) as f:\n",
    "        programs.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622dbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d191aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Files mit Partei einlesen und speichern\n",
    "path = '../data/wahlprogramme/'\n",
    "programs = []\n",
    "for file_path in os.listdir(path):\n",
    "    # Extrahiere die Partei\n",
    "    party = file_path.replace('.txt', '').lower()\n",
    "    # Einlesen der Datei\n",
    "    with open(path + file_path) as f:     \n",
    "        program = f.read()\n",
    "    data = {'party': party, 'text': program}\n",
    "    programs.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eefba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe66b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24925cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04a42f",
   "metadata": {},
   "source": [
    "## Text säubern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c086c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp_text.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ebdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f946f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(fdp_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2e5fb",
   "metadata": {},
   "source": [
    "### Auf alle Wahlprogramme im Dataframe anwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f5eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880d28d",
   "metadata": {},
   "source": [
    "## Text Analyse\n",
    "\n",
    "nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e6d1d",
   "metadata": {},
   "source": [
    "### Anzahl der Sätze und Anzahl der Wörter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "sentences = sent_tokenize(fdp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sentences(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentences_count'] = df['clean_text'].apply(count_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a47e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e301e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "words = word_tokenize(fdp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1294e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d846ba8",
   "metadata": {},
   "source": [
    "#### Satzzeichen entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868663e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "satzzeichen = ['.', ',', '?', ':', ';', '!', '-']\n",
    "\n",
    "clean_words = []\n",
    "for word in words:\n",
    "    if word not in satzzeichen:\n",
    "        clean_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion clean_words\n",
    "\n",
    "def clean_words(text, exclude):\n",
    "    words = word_tokenize(text)\n",
    "    clean_words = []\n",
    "    for word in words:\n",
    "        if word not in exclude:\n",
    "            clean_words.append(word)\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc541af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "satzzeichen = ['.', ',', '?', ':', ';', '!', '-']\n",
    "df['words'] = df['clean_text'].apply(clean_words, exclude=satzzeichen)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca1dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['words'].apply(len)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f5946d",
   "metadata": {},
   "source": [
    "### Most frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp_words = df.loc[4, 'words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eccfefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdp_words = df.loc[4, 'words']\n",
    "fdist = FreqDist(fdp_words)\n",
    "fdist.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d2f0b",
   "metadata": {},
   "source": [
    "### Anpassungen der clean_words Funktion\n",
    "\n",
    "- Weiter Satzzeichen (, ), \", entfernen\n",
    "- alle Wörter kleinschreiben\n",
    "- Füllwörter entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion clean_words\n",
    "def clean_words(text, exclude=satzzeichen):\n",
    "    words = word_tokenize(text)\n",
    "    clean_words = []\n",
    "    for word in words:\n",
    "        if word not in exclude:\n",
    "            clean_words.append(word.lower())\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0cf722",
   "metadata": {},
   "outputs": [],
   "source": [
    "satzzeichen = ['.', ',', '?', ':', ';', '!', '-', '(', ')', '\"', \"“\", '„', '–']\n",
    "df['words'] = df['clean_text'].apply(clean_words, exclude=satzzeichen)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7634be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdp_words = df.loc[4, 'words']\n",
    "fdist = FreqDist(fdp_words)\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae7cc40",
   "metadata": {},
   "source": [
    "### Füllwörter entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92fae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = stopwords.words('german')\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95172251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion clean_words\n",
    "def clean_words(text, exclude):\n",
    "    words = word_tokenize(text)\n",
    "    clean = []\n",
    "    for word in words:\n",
    "        if word.lower() not in exclude:\n",
    "            clean.append(word.lower())\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790c5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "satzzeichen = ['.', ',', '?', ':', ';', '!', '-', '(', ')', '\"', \"“\", '„', '–', '•', '', '*']\n",
    "exclude = satzzeichen + stopwords\n",
    "\n",
    "df['words'] = df['clean_text'].apply(clean_words, exclude=exclude)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa13c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_words(words, n=20):\n",
    "    fdist = FreqDist(words)\n",
    "    return fdist.most_common(n)\n",
    "\n",
    "fdp_words = df.loc[4, 'words']\n",
    "most_common_words(fdp_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c7a515",
   "metadata": {},
   "source": [
    "## Wortwolken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f09522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_word_clouds(freq_dict):\n",
    "    wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate_from_frequencies(freq_dict)\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de77ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp_top_words = most_common_words(fdp_words)\n",
    "generate_word_clouds(dict(fdp_top_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53306128",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    print(row['party'])\n",
    "    top_words = most_common_words(row['words'], n=40)\n",
    "    generate_word_clouds(dict(top_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f84df",
   "metadata": {},
   "source": [
    "## Mehrere Wörter - Bigrams und Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039bbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "bigrams = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8225a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp_words = df.loc[1, 'words']\n",
    "bigrams = list(nltk.bigrams(fdp_words))\n",
    "\n",
    "fdist = FreqDist(bigrams)\n",
    "fdist.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee44663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp_words = df.loc[1, 'words']\n",
    "bigrams = list(nltk.trigrams(fdp_words))\n",
    "\n",
    "fdist = FreqDist(bigrams)\n",
    "fdist.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_words(words, n=20, ngrams=''):\n",
    "    if ngrams == 'bigrams':\n",
    "        words = list(nltk.bigrams(words))\n",
    "    if ngrams == 'trigrams':\n",
    "        words = list(nltk.trigrams(words))\n",
    "    fdist = FreqDist(words)\n",
    "    return fdist.most_common(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2c630",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    print(row['party'])\n",
    "    top_words = most_common_words(row['words'], n=20, ngrams='bigrams')\n",
    "    for idx, word_freq in enumerate(top_words):\n",
    "        if type(word_freq[0]) != str:\n",
    "            top_words[idx] = (' '.join(word_freq[0]), word_freq[1])\n",
    "    generate_word_clouds(dict(top_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5662b6fd",
   "metadata": {},
   "source": [
    "# Kurs Evaluation\n",
    "\n",
    "https://ahaslides.com/C7S01\n",
    "\n",
    "![Kurs Evaluation](../imgs/qr_evaluation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e089e68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
